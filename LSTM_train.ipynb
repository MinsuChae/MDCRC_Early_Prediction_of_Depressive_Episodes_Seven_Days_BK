{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4def7e95-6fea-4876-ba9a-257faa7c338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "demography_df = pd.read_csv(\"patient_demographic.csv\")\n",
    "demography_df['date'] = pd.to_datetime(demography_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de38208d-2b23-4a75-ac66-15b6c8b3f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 5571"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c6ab3c-e3cc-47cc-8639-7ff8e1590ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_dats(df, seed):\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=seed, stratify=df['Label'])\n",
    "    train_df, early_df = train_test_split(train_df, test_size=len(test_df), random_state=seed, stratify=train_df['Label'])\n",
    "    \n",
    "    del train_df['Label']\n",
    "    del early_df['Label']\n",
    "    del test_df['Label']\n",
    "\n",
    "\n",
    "    return train_df, early_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cf5ddd-b5e0-4f36-a2c5-523ed76b1428",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, early_df, test_df = split_dats(demography_df, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f401108c-2fd3-4e54-9a6d-2cf2f25aec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_age(row):\n",
    "    return row['timestamp'].year - row['date'].year + row['age']\n",
    "    \n",
    "df = pd.read_csv(\"feature_selected.csv\")\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "\n",
    "train_df = pd.merge(df, train_df, on='patient_id')\n",
    "train_df['age'] = train_df.apply(calc_age, axis=1)\n",
    "train_df.insert(4,'age2',0)\n",
    "train_df.insert(5,'sex2',0)\n",
    "train_df['sex2'] = train_df['sex']\n",
    "train_df['age2'] = train_df['age']\n",
    "train_df.drop(['age','sex','date'], axis=1, inplace=True)\n",
    "train_df.rename(columns={'age2':'age','sex2':'sex'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb7ac2c-aedd-45ae-bc61-5de9651bb49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_df = pd.merge(df, early_df, on='patient_id')\n",
    "early_df['age'] = early_df.apply(calc_age, axis=1)\n",
    "early_df.insert(4,'age2',0)\n",
    "early_df.insert(5,'sex2',0)\n",
    "early_df['sex2'] = early_df['sex']\n",
    "early_df['age2'] = early_df['age']\n",
    "early_df.drop(['age','sex','date'], axis=1, inplace=True)\n",
    "early_df.rename(columns={'age2':'age','sex2':'sex'}, inplace=True)\n",
    "\n",
    "test_df = pd.merge(df, test_df, on='patient_id')\n",
    "test_df['age'] = test_df.apply(calc_age, axis=1)\n",
    "test_df.insert(4,'age2',0)\n",
    "test_df.insert(5,'sex2',0)\n",
    "test_df['sex2'] = test_df['sex']\n",
    "test_df['age2'] = test_df['age']\n",
    "test_df.drop(['age','sex','date'], axis=1, inplace=True)\n",
    "test_df.rename(columns={'age2':'age','sex2':'sex'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed37d4f5-f06a-4e09-b89c-6c47240f83d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature(df):\n",
    "    patients = np.unique(df['patient_id'])\n",
    "    feature = []\n",
    "    target = []\n",
    "    \n",
    "    for p in patients:\n",
    "        df_tmp = df[df['patient_id']==p]\n",
    "        arr = df_tmp.values[:, :]\n",
    "        \n",
    "        for i in range(7, len(arr)-7):\n",
    "            tmp_f = arr[i-7:i, 2:-1]\n",
    "            tmp_t = arr[i+6,-1]\n",
    "    \n",
    "            if pd.isna(tmp_t) or pd.isna(tmp_f).sum() >= 1:\n",
    "                continue\n",
    "    \n",
    "            feature.append(tmp_f)\n",
    "            target.append(tmp_t)\n",
    "\n",
    "    return np.array(feature).astype(float), np.array(target).reshape(-1, 1)\n",
    "\n",
    "train_feature, train_target = make_feature(train_df)\n",
    "earlystop_feature, earlystop_target = make_feature(early_df)\n",
    "test_feature, test_target = make_feature(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15bf3cf-7b15-4970-92b9-bd2aad25f2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.unique(train_target, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7864014-4a96-40f2-a21a-bfb6c202c8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "max_count = np.max(tmp[1])\n",
    "\n",
    "my_dict = {}\n",
    "for i in range(len(tmp[0])):\n",
    "    k = tmp[0][i]\n",
    "    v = tmp[1][i]\n",
    "    if i == 0:\n",
    "        my_dict[k] = v * (len(tmp[0])) * 4\n",
    "    else:\n",
    "        my_dict[k] = round(v * math.ceil(max_count/v) * 5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36341bfb-1860-4dd1-bf3c-eb2edcde80c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = train_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0320bd71-aae5-4d5c-be1c-4a2033c93970",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "train_feature = train_feature.reshape(len(train_feature), -1)\n",
    "earlystop_feature = earlystop_feature.reshape(len(earlystop_feature), -1)\n",
    "test_feature = test_feature.reshape(len(test_feature), -1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_feature = scaler.fit_transform(train_feature)\n",
    "earlystop_feature = scaler.transform(earlystop_feature)\n",
    "test_feature = scaler.transform(test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cf6eba-1df2-4153-b3fe-bdb425bd31c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state = seed, sampling_strategy=my_dict)\n",
    "try:\n",
    "    train_feature_SMOTE, train_target_SMOTE = sm.fit_resample(train_feature, train_target)\n",
    "    train_target_SMOTE = train_target_SMOTE.reshape(len(train_target_SMOTE),1)\n",
    "except:\n",
    "    try:\n",
    "        sm = SMOTE(random_state = seed, sampling_strategy=my_dict, k_neighbors=4)\n",
    "        train_feature_SMOTE, train_target_SMOTE = sm.fit_resample(train_feature, train_target)\n",
    "        train_target_SMOTE = train_target_SMOTE.reshape(len(train_target_SMOTE),1)\n",
    "    except:\n",
    "        try:\n",
    "            sm = SMOTE(random_state = seed, sampling_strategy=my_dict, k_neighbors=3)\n",
    "            train_feature_SMOTE, train_target_SMOTE = sm.fit_resample(train_feature, train_target)\n",
    "            train_target_SMOTE = train_target_SMOTE.reshape(len(train_target_SMOTE),1)\n",
    "        except:\n",
    "            try:\n",
    "                sm = SMOTE(random_state = seed, sampling_strategy=my_dict, k_neighbors=2)\n",
    "                train_feature_SMOTE, train_target_SMOTE = sm.fit_resample(train_feature, train_target)\n",
    "                train_target_SMOTE = train_target_SMOTE.reshape(len(train_target_SMOTE),1)\n",
    "            except:\n",
    "                sm = SMOTE(random_state = seed, sampling_strategy=my_dict, k_neighbors=1)\n",
    "                train_feature_SMOTE, train_target_SMOTE = sm.fit_resample(train_feature, train_target)\n",
    "                train_target_SMOTE = train_target_SMOTE.reshape(len(train_target_SMOTE),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0354ff-70c7-47a1-a89b-c6c6d20c2c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_SMOTE = train_feature_SMOTE.reshape(len(train_feature_SMOTE), shape[1], shape[2]).astype(float)\n",
    "earlystop_feature = earlystop_feature.reshape(len(earlystop_feature), shape[1], shape[2]).astype(float)\n",
    "test_feature = test_feature.reshape(len(test_feature), shape[1], shape[2]).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01468b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_multi_label(arr_target):\n",
    "    tmp_target = []\n",
    "    for i in range(len(arr_target)):\n",
    "        row = []\n",
    "        if arr_target[i][0] == 0:\n",
    "            row.append(0)\n",
    "        elif arr_target[i][0] == 1:\n",
    "            row.append(1)\n",
    "        elif arr_target[i][0] == 2:\n",
    "            row.append(1)\n",
    "        elif arr_target[i][0] == 4:\n",
    "            row.append(1)\n",
    "\n",
    "        tmp_target.append(row)\n",
    "\n",
    "    return np.array(tmp_target).reshape(len(tmp_target), -1)\n",
    "\n",
    "train_target_SMOTE = make_multi_label(train_target_SMOTE)\n",
    "earlystop_target = make_multi_label(earlystop_target)\n",
    "test_target = make_multi_label(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1598f90b-7c25-46c1-adf5-5b1d70c67ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Masking, LSTM, Dropout, MultiHeadAttention, Flatten, Dense, LayerNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.metrics import Precision, Recall, PrecisionAtRecall\n",
    "from tensorflow.keras.losses import BinaryFocalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "input_layer = Input(shape=shape[1:])\n",
    "\n",
    "layer_01_lstm = LSTM(32, return_sequences=True)(input_layer)\n",
    "layer_02_dropout = Dropout(0.2)(layer_01_lstm)\n",
    "\n",
    "layer_03_lstm = LSTM(24, return_sequences=True)(layer_02_dropout)\n",
    "layer_04_dropout = Dropout(0.2)(layer_03_lstm)\n",
    "\n",
    "layer_05_lstm = LSTM(16, return_sequences=True)(layer_04_dropout)\n",
    "layer_06_dropout = Dropout(0.2)(layer_05_lstm)\n",
    "\n",
    "layer_07_lstm = LSTM(8, return_sequences=True)(layer_06_dropout)\n",
    "layer_08_dropout = Dropout(0.2)(layer_07_lstm)\n",
    "\n",
    "layer_attention = MultiHeadAttention(num_heads=16, key_dim=16)(layer_08_dropout, layer_08_dropout)\n",
    "layer_flatten = Flatten()(layer_attention)\n",
    "\n",
    "layer_09_dense = Dense(96,  activation='relu')(layer_flatten)\n",
    "layer_10_dropout = Dropout(0.2)(layer_09_dense)\n",
    "layer_11_normalization = LayerNormalization()(layer_10_dropout)\n",
    "\n",
    "layer_12_dense = Dense(64,  activation='relu')(layer_11_normalization)\n",
    "layer_13_dropout = Dropout(0.2)(layer_12_dense)\n",
    "layer_14_normalization = LayerNormalization()(layer_13_dropout)\n",
    "\n",
    "layer_15_dense = Dense(32,  activation='relu')(layer_14_normalization)\n",
    "layer_16_dropout = Dropout(0.2)(layer_15_dense)\n",
    "layer_17_normalization = LayerNormalization()(layer_16_dropout)\n",
    "\n",
    "layer_depressive = Dense(1, activation='sigmoid', name='depressive')(layer_17_normalization)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=layer_depressive)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=ExponentialDecay(0.000001, decay_steps=1000, decay_rate=0.99)), loss=BinaryFocalCrossentropy(), metrics=[Precision(), Recall(), PrecisionAtRecall(0.7)])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e179f46a-cbf9-4b4b-9d8e-b582cf4eede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_recall',mode='max', patience=10, verbose=1,restore_best_weights=True, start_from_epoch=5)\n",
    "model.fit(train_feature_SMOTE, train_target_SMOTE, epochs = 1000, verbose=1, validation_data=(earlystop_feature, earlystop_target), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609b6fd4-0d6e-4244-8427-16b5d9ad686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, precision_recall_curve, auc\n",
    "\n",
    "\n",
    "y_pred_proba = model.predict(test_feature)\n",
    "y_pred = np.round(y_pred_proba)\n",
    "\n",
    "precision = precision_score(test_target, y_pred)\n",
    "recall = recall_score(test_target, y_pred)\n",
    "f1 = f1_score(test_target, y_pred)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(test_target, y_pred_proba)\n",
    "auroc = auc(fpr, tpr)\n",
    "precision_prc, recall_prc, thresholds = precision_recall_curve(test_target, y_pred_proba)\n",
    "auprc = auc(recall_prc, precision_prc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dcc78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[precision, recall, f1, auroc, auprc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b5a330-074d-43f4-83be-443f84c0ba3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('LSTM_Feature_DLMO_CR_{}.h5'.format(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33aa6f4-773c-4c7c-94ee-712f6a4da2f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
